import json
import pandas as pd
import numpy as np
from sklearn.feature_selection import mutual_info_classif
from scipy.stats import chi2_contingency
import matplotlib.pyplot as plt
import seaborn as sns

def load_jsonl_data(file_path):
    records = []

    with open(file_path, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
        for entry in raw_data:
            try:
                if "explanations" in entry and "qualitative" in entry["explanations"]:
                    q = entry["explanations"]["qualitative"]
                    records.append({
                        "index": entry.get("index", None),
                        "label": entry.get("label", None),
                        "fund_flow": 1 if q["fund_flow"].lower() == "yes" else 0,
                        "profit_logic": 1 if q["profit_logic"].lower() == "yes" else 0,
                        "referral_mechanism": 1 if q["referral_mechanism"].lower() == "yes" else 0,
                        "withdrawal_control": 1 if q["withdrawal_control"].lower() == "yes" else 0,
                        "camouflage": 1 if q["camouflage"].lower() == "yes" else 0,
                    })
            except json.JSONDecodeError:
                continue
    return pd.DataFrame(records)


def full_statistical_analysis(df):
    features = ["fund_flow", "profit_logic", "referral_mechanism", "withdrawal_control", "camouflage"]
    X = df[features]
    y = df["label"]

    # === 2. å¡æ–¹æ£€éªŒ ===
    chi2_results = []
    for feature in features:
        contingency_table = pd.crosstab(X, y)
        chi2, p, _, _ = chi2_contingency(contingency_table)
        chi2_results.append({
            "Feature": feature,
            "Chi2 Statistic": chi2,
            "p-value": p,
            "Significant (p < 0.05)": "âœ“" if p < 0.05 else "âœ—"
        })

    # æ„å»º DataFrameï¼Œå¹¶æŠŠ Feature è®¾ä¸ºè¡Œç´¢å¼•
    chi_df = pd.DataFrame(chi2_results).set_index("Feature")

    # åªç”» p-valueï¼Œä¸€åˆ—çš„çƒ­åŠ›å›¾ï¼Œçºµè½´å°±æ˜¯ Feature
    plt.figure(figsize=(6, len(features) * 0.4))  # æ ¹æ®ç‰¹å¾æ•°é‡åŠ¨æ€è°ƒæ•´é«˜åº¦
    sns.heatmap(
        chi_df[["p-value"]],
        annot=True,
        cmap="Blues_r",
        cbar=True,
        yticklabels=True
    )
    plt.title("p-value Heatmap from Chi-Square Test")
    plt.ylabel("Feature")
    plt.tight_layout()
    plt.show()

    # === 3. å¡æ–¹çƒ­åŠ›å›¾å±•ç¤º ===
    plt.figure(figsize=(6, 4))
    sns.heatmap(chi_df[["Chi2 Statistic"]], annot=True, cmap="YlOrRd", cbar=True)
    plt.title("Chi-Square Statistics per Feature")
    plt.tight_layout()
    plt.show()

def formalize_column_names(df: pd.DataFrame, rename_dict: dict) -> pd.DataFrame:
    """
    ä¿®æ”¹DataFrameçš„åˆ—åï¼šå¦‚æœæ—§åˆ—åå­˜åœ¨ï¼Œåˆ™æ”¹ä¸ºæ–°åˆ—åã€‚

    å‚æ•°ï¼š
        df (pd.DataFrame): åŸå§‹DataFrame
        rename_dict (dict): æ˜ å°„å­—å…¸ï¼Œkeyä¸ºæ—§åˆ—åï¼Œvalueä¸ºæ–°åˆ—åï¼ˆå½¢å¼åŒ–åçš„ï¼‰

    è¿”å›ï¼š
        pd.DataFrame: ä¿®æ”¹åˆ—ååçš„DataFrame
    """
    rename_mapping = {old: new for old, new in rename_dict.items() if old in df.columns}
    return df.rename(columns=rename_mapping)


def compute_chi2_cramers(df):
    """
    è®¡ç®—æ¯ä¸ªç‰¹å¾ä¸æ ‡ç­¾ä¹‹é—´çš„å¡æ–¹ç»Ÿè®¡é‡ã€è‡ªç”±åº¦ã€p-value å’Œ CramÃ©r's Vã€‚

    å‚æ•°:
        df (pd.DataFrame): åŒ…å«ç‰¹å¾å’Œæ ‡ç­¾çš„æ•°æ®æ¡†
        features (list of str): ç‰¹å¾åˆ—ååˆ—è¡¨
        label (str): æ ‡ç­¾åˆ—åï¼Œé»˜è®¤ä¸º 'label'

    è¿”å›:
        pd.DataFrame: åŒ…å« ['Feature','Chi2 Statistic','df','p-value',"CramÃ©r's V"] åˆ—çš„ç»“æœè¡¨ï¼ŒæŒ‰ Chi2 å€¼é™åºæ’åº
    """
    features = ["fund_flow", "profit_logic", "referral_mechanism", "withdrawal_control", "camouflage"]
    label = df["label"]
    results = []
    old_to_formal_name = {
        "fund_flow": "Fund Flow",
        "profit_logic": "Profit Logic",
        "referral_mechanism": "Referral Mechanism",
        "withdrawal_control": "Withdrawal Control",
        "camouflage": "Camouflage Naming"
    }
    df = formalize_column_names(df, old_to_formal_name)
    features = list(old_to_formal_name.values())
    for feature in features:
        contingency = pd.crosstab(df[feature], label)
        chi2, p, dof, _ = chi2_contingency(contingency)
        n = contingency.values.sum()
        r, k = contingency.shape
        cramers_v = np.sqrt(chi2 / (n * min(r-1, k-1)))

        results.append({
            'Feature': feature,
            'Chi2 Statistic': chi2,
            'df': dof,
            'p-value': p,
            "CramÃ©r's V": cramers_v
        })
    results_df = pd.DataFrame(results).sort_values('Chi2 Statistic', ascending=False)
    results_df.to_excel('chi2_results.xlsx', index=False)

    # 1. é¢„å¤„ç†ï¼šè®¡ç®— -log10(p-value) å¹¶æ ‡è®°æ˜¾è‘—æ€§
    results_df['neg_log10_p'] = -np.log10(results_df['p-value'])
    results_df['significant'] = results_df['p-value'] < 0.05

    # 2. æ’åºï¼šæŒ‰æ˜¾è‘—æ€§åŠ neg_log10_p æ’åºï¼Œé‡è¦ç‰¹å¾é å‰
    plot_df = (results_df
               .sort_values(['significant', 'neg_log10_p'],
                            ascending=[False, False]))

    # 3. å…¨å±€é£æ ¼è®¾ç½®
    sns.set_style("white")  # çº¯ç™½èƒŒæ™¯
    sns.set_context("paper", font_scale=1.3)  # è®ºæ–‡çº§å­—å·
    plt.rcParams["font.family"] = "sans-serif"
    plt.rcParams["font.sans-serif"] = ["Arial", "DejaVu Sans"]
    plt.rcParams["axes.linewidth"] = 0.8  # è½´çº¿åŠ ç²—
    plt.rcParams["xtick.direction"] = "out"  # åˆ»åº¦æœå¤–
    plt.rcParams["ytick.direction"] = "out"

    # 4. ä½œå›¾
    fig, ax = plt.subplots(figsize=(8, 6))

    # å•è‰²æ¡å½¢ï¼Œæ˜¾è‘—æ€§ç”¨æ·±æµ…åŒºåˆ†
    palette = ['#7f7f7f' if not sig else '#1f77b4'
               for sig in plot_df['significant']]

    bars = ax.bar(
        x=plot_df['Feature'],
        height=plot_df['neg_log10_p'],
        color=palette,
        edgecolor='black',
        linewidth=0.05
    )

    # 5. æ ‡æ³¨æ¯ä¸ªæ¡çš„æ•°å€¼
    for bar, val in zip(bars, plot_df['neg_log10_p']):
        ax.text(
            bar.get_x() + bar.get_width() / 2,  # x ä½ç½®å±…ä¸­
            val + 0.05,  # y å€¼ç•¥ä¸Šæ–¹
            f"{val:.2f}",
            ha='center',
            va='bottom',
            fontsize=12
        )

    # 6. æ˜¾è‘—æ€§é˜ˆå€¼çº¿
    threshold = -np.log10(0.05)
    ax.axhline(threshold, color='black', linestyle='--', linewidth=1)
    ax.text(
        len(plot_df) - 0.05, threshold + 0.05,
        "p = 0.05",
        ha='right',
        va='bottom',
        fontsize=12,
        color='black'
    )

    # 7. åæ ‡è½´ä¸æ ‡é¢˜
    ax.set_xlabel("")  # x è½´æ ‡ç­¾ä¸ºç©ºï¼Œç”±ä¸‹æ–¹æ³¨é‡Šè¯´æ˜
    ax.set_ylabel("-log10(p-value)", fontsize=14)
    # ax.set_ylabel(r"$-\log_{10}(p\text{-value})$")
    # ax.set_title("Feature Significance by Chiâ€“Square Test", fontsize=14, pad=15)

    # 8. ç»†èŠ‚ä¼˜åŒ–
    ax.set_xticks(range(len(plot_df)))
    ax.set_xticklabels(plot_df['Feature'], rotation=45, ha='right', fontsize=11)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.grid(axis='y', linestyle=':', linewidth=0.7, alpha=0.7)
    ax.tick_params(axis='x', labelsize=12)

    # 9. å›¾ä¾‹è¯´æ˜ï¼ˆæ‰‹åŠ¨æ·»åŠ ï¼‰
    import matplotlib.patches as mpatches
    legend_patches = [
        mpatches.Patch(facecolor='#1f77b4', edgecolor='black', label='p < 0.05'),
        mpatches.Patch(facecolor='#7f7f7f', edgecolor='black', label='p â‰¥ 0.05')
    ]
    ax.legend(
        handles=legend_patches,
        title="Significance",
        loc='upper right',
        frameon=False,
        fontsize=13,
        title_fontsize=11
    )

    plt.tight_layout()
    plt.savefig("chi2_pvalue_barplot.png", dpi=300, bbox_inches="tight")
    plt.show()

# ------------------------
# ä½¿ç”¨ç¤ºä¾‹ï¼ˆè¯·ç¡®ä¿ df å’Œ features å·²å®šä¹‰ï¼‰:
# ------------------------
# features = ['featureA', 'featureB', 'featureC', 'featureD', 'featureE']
# results_df = compute_chi2_cramers(df, features, label='label')
# import ace_tools as tools; tools.display_dataframe_to_user("Chi-Square Test Results", results_df)




# Re-import required modules after environment reset
# import json
# import pandas as pd
# from sklearn.model_selection import train_test_split
# from xgboost import XGBClassifier, plot_importance
# from sklearn.metrics import classification_report
# import matplotlib.pyplot as plt
#
# def model_with_xgboost_metrics(df):
#     features = ["fund_flow", "profit_logic", "referral_mechanism", "withdrawal_control", "camouflage"]
#     X = df[features].to_numpy()
#     y = df["label"].to_numpy()
#
#     # æ•°æ®åˆ’åˆ†
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
#
#     # æ¨¡å‹è®­ç»ƒ
#     model = XGBClassifier(use_label_encoder=False, eval_metric="logloss")
#     model.fit(X_train, y_train)
#
#     # æµ‹è¯•é›†é¢„æµ‹ + åˆ†ç±»æŒ‡æ ‡
#     y_pred = model.predict(X_test)
#     report = classification_report(y_test, y_pred, output_dict=True)
#     report_df = pd.DataFrame(report).T[["precision", "recall", "f1-score"]]
#
#     # æ‰“å°æŒ‡æ ‡
#     print("=== Classification Report on Test Set ===")
#     print(report_df)
#
#     # å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§
#     plt.figure(figsize=(8, 4))
#     plot_importance(model, importance_type="weight", xlabel="Feature Importance", title="XGBoost Feature Importance")
#     plt.tight_layout()
#     plt.show()
#
#     return report_df


import json

def calculate_camouflage_ratio(json_file_path):
    with open(json_file_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    total_ponzi = 0
    ponzi_with_camouflage = 0

    for item in data:
        label = item.get("label", 0)
        camouflage = item.get("explanations", {}).get("qualitative", "").get("camouflage", "").strip().lower()

        if label == 1 or label == "ponzi":  # æ”¯æŒæ•°å­—æˆ–å­—ç¬¦ä¸²æ ‡æ³¨
            total_ponzi += 1
            if camouflage == "yes":
                ponzi_with_camouflage += 1

    if total_ponzi == 0:
        print("No Ponzi contracts found.")
        return

    ratio = ponzi_with_camouflage / total_ponzi
    print(f"ğŸ’¡ Total Ponzi contracts        : {total_ponzi}")
    print(f"ğŸ” With naming camouflage       : {ponzi_with_camouflage}")
    print(f"ğŸ“Š Camouflage ratio (Ponzi only): {ratio:.4f} ({ratio * 100:.2f}%)")





if __name__ == '__main__':
    data_path = r'llm_explanations.json'
    datasets = load_jsonl_data(data_path)
    # full_statistical_analysis(datasets)
    compute_chi2_cramers(datasets)
    # model_with_xgboost_metrics(datasets)

    # calculate_camouflage_ratio(data_path)